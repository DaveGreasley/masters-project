{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from skmultilearn.problem_transform import BinaryRelevance, ClassifierChain, LabelPowerset\n",
    "    \n",
    "from common.featuresutils import load_features\n",
    "from common.flagutils import load_flag_list\n",
    "from common.flagutils import load_o3_flags\n",
    "from common.flagutils import build_config\n",
    "from common.flagutils import get_cmd_string_from_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Benchmark</th>\n",
       "      <th>Flags</th>\n",
       "      <th>Type</th>\n",
       "      <th>RunId</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BT.C</td>\n",
       "      <td>-O3</td>\n",
       "      <td>O3</td>\n",
       "      <td>-1</td>\n",
       "      <td>8685.049255</td>\n",
       "      <td>44.226147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BT.C</td>\n",
       "      <td>-O3 -faggressive-loop-optimizations -falign-fu...</td>\n",
       "      <td>test</td>\n",
       "      <td>80</td>\n",
       "      <td>8776.150006</td>\n",
       "      <td>43.287949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BT.C</td>\n",
       "      <td>-O3 -faggressive-loop-optimizations -falign-fu...</td>\n",
       "      <td>test</td>\n",
       "      <td>82</td>\n",
       "      <td>8918.038919</td>\n",
       "      <td>43.911705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BT.C</td>\n",
       "      <td>-O3 -faggressive-loop-optimizations -falign-fu...</td>\n",
       "      <td>test</td>\n",
       "      <td>83</td>\n",
       "      <td>8861.715663</td>\n",
       "      <td>43.573321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BT.C</td>\n",
       "      <td>-O3 -faggressive-loop-optimizations -falign-fu...</td>\n",
       "      <td>test</td>\n",
       "      <td>84</td>\n",
       "      <td>8867.013709</td>\n",
       "      <td>43.667829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Benchmark                                              Flags  Type  RunId  \\\n",
       "0      BT.C                                                -O3    O3     -1   \n",
       "1      BT.C  -O3 -faggressive-loop-optimizations -falign-fu...  test     80   \n",
       "2      BT.C  -O3 -faggressive-loop-optimizations -falign-fu...  test     82   \n",
       "3      BT.C  -O3 -faggressive-loop-optimizations -falign-fu...  test     83   \n",
       "4      BT.C  -O3 -faggressive-loop-optimizations -falign-fu...  test     84   \n",
       "\n",
       "        Energy       Time  \n",
       "0  8685.049255  44.226147  \n",
       "1  8776.150006  43.287949  \n",
       "2  8918.038919  43.911705  \n",
       "3  8861.715663  43.573321  \n",
       "4  8867.013709  43.667829  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('CE.results.csv')\n",
    "data.loc[:, 'Energy'] *= 1e-6 # Convert energy to Joules\n",
    "data.loc[:, 'Benchmark'] = data['Benchmark'].str.replace('.x', '')\n",
    "\n",
    "average_data = data.groupby(['Benchmark','Flags', 'Type', 'RunId'], as_index=False).agg({'Energy':'mean', 'Time':'mean'})\n",
    "average_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n"
     ]
    }
   ],
   "source": [
    "all_flags = load_flag_list()\n",
    "print(len(all_flags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_configuration(variable, benchmark, average_data):\n",
    "    benchmark_data = average_data.loc[average_data[\"Benchmark\"] == benchmark]\n",
    "    min_index = benchmark_data[variable].idxmin()\n",
    "    return benchmark_data.loc[min_index][\"Flags\"]\n",
    "\n",
    "\n",
    "def get_o3_config():\n",
    "    return get_cmd_string_from_config(build_config(all_flags, load_o3_flags(), '-O3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nab', 'imagick', 'botsalgn', 'botsspar', 'kdtree', 'smithwa', 'BT', 'UA', 'swim', 'EP']\n"
     ]
    }
   ],
   "source": [
    "benchmarks = data[\"Benchmark\"].unique()\n",
    "benchmarks_nosize = [b.split('.')[0] for b in benchmarks]\n",
    "print(benchmarks_nosize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(with_dwarf):\n",
    "    X = StandardScaler().fit_transform(load_features(benchmarks_nosize, with_dwarf=with_dwarf))\n",
    "    y = []\n",
    "\n",
    "    for benchmark in benchmarks:\n",
    "        config_str = best_configuration('Energy', benchmark, average_data)\n",
    "        if config_str == '-O3':\n",
    "            config_str = get_o3_config()\n",
    "\n",
    "        labels = []\n",
    "\n",
    "        config = config_str[4:].split(' ')\n",
    "        for i, flag in enumerate(config):\n",
    "            if flag == all_flags[i]:\n",
    "                labels.append(1) # Flag is turned on\n",
    "            elif flag == '-fno-' + all_flags[i][2:]:\n",
    "                labels.append(0) # FLag is turned off -fno\n",
    "            else:\n",
    "                print(\"ERROR:\" + flag)\n",
    "\n",
    "        y.append(labels)\n",
    "\n",
    "    return X, np.array(y)\n",
    "\n",
    "\n",
    "def remove_static_labels(y):\n",
    "    '''Removes any columns that are the same for all samples'''\n",
    "    cols_to_remove = []\n",
    "    for i in range(y.shape[1]):\n",
    "        unique, counts = np.unique(y[:, i], return_counts=True)\n",
    "\n",
    "        if (len(unique) == 1) or (1 in counts):\n",
    "            cols_to_remove.append(i)\n",
    "\n",
    "    return np.delete(y, cols_to_remove, axis=1)\n",
    "\n",
    "\n",
    "def grid_search(classifier, parameters, X, y):\n",
    "    gs = GridSearchCV(classifier, parameters, cv=10, scoring='f1_macro', n_jobs=-1)\n",
    "    gs.fit(X, y)\n",
    "\n",
    "    return gs\n",
    "\n",
    "\n",
    "def test_multilabel_classifier(classifier, X, y):\n",
    "    classifier_name = type(classifier).__name__\n",
    "    \n",
    "    print(f\"Testing {classifier_name}\")\n",
    "    \n",
    "    parameters = [\n",
    "        {\n",
    "            'classifier': [SVC(kernel='linear')],\n",
    "            'classifier__C': np.logspace(-2, 10, 13)\n",
    "        },\n",
    "        {\n",
    "            'classifier': [SVC(kernel='rbf')],\n",
    "            'classifier__C': np.logspace(-2, 10, 13), \n",
    "            'classifier__gamma':  np.logspace(-9, 3, 13)\n",
    "        },\n",
    "        {\n",
    "            'classifier': [GaussianNB(), DecisionTreeClassifier(max_depth=5), AdaBoostClassifier(), DecisionTreeClassifier(max_depth=5)]\n",
    "        }\n",
    "    ]\n",
    "    gs = grid_search(classifier, parameters, X, y)\n",
    "\n",
    "    print(f\"{classifier_name} Best F1 Score: {gs.best_score_}\")\n",
    "    print(gs.best_params_)\n",
    "    print(\"---------\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_comparison(multilabel_classifiers, disable_warnings=False, with_dwarf=False):\n",
    "    X, y = load_data(with_dwarf)\n",
    "    y = remove_static_labels(y)\n",
    "\n",
    "    print(f\"Loaded {X.shape[0]} samples with {X.shape[1]} features and {y.shape[1]} labels.\")\n",
    "    \n",
    "    # Grid search can throw a lot of warnings. Is useful to just mute them sometimes.\n",
    "    if disable_warnings:\n",
    "        import warnings\n",
    "        warnings.filterwarnings('ignore')\n",
    "        \n",
    "    for clf in multilabel_classifiers:\n",
    "        test_multilabel_classifier(clf, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 samples with 65 features and 85 labels.\n",
      "Testing BinaryRelevance\n",
      "BinaryRelevance Best F1 Score: 0.6517647058823529\n",
      "{'classifier': SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=1e-09, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), 'classifier__C': 0.01, 'classifier__gamma': 1e-09}\n",
      "---------\n",
      "Testing ClassifierChain\n",
      "ClassifierChain Best F1 Score: 0.6529411764705882\n",
      "{'classifier': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=1.0, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), 'classifier__C': 1.0, 'classifier__gamma': 1.0}\n",
      "---------\n",
      "Testing LabelPowerset\n",
      "LabelPowerset Best F1 Score: 0.6047058823529412\n",
      "{'classifier': SVC(C=100000000.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=1e-09, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), 'classifier__C': 100000000.0, 'classifier__gamma': 1e-09}\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "run_comparison([BinaryRelevance(), ClassifierChain(), LabelPowerset()], disable_warnings=True, with_dwarf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 samples with 66 features and 85 labels.\n",
      "Testing BinaryRelevance\n",
      "BinaryRelevance Best F1 Score: 0.6517647058823529\n",
      "{'classifier': SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=1e-09, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), 'classifier__C': 0.01, 'classifier__gamma': 1e-09}\n",
      "---------\n",
      "Testing ClassifierChain\n",
      "ClassifierChain Best F1 Score: 0.6529411764705882\n",
      "{'classifier': SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), 'classifier__C': 0.01}\n",
      "---------\n",
      "Testing LabelPowerset\n",
      "LabelPowerset Best F1 Score: 0.4705882352941176\n",
      "{'classifier': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), 'classifier__C': 1.0}\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "run_comparison([BinaryRelevance(), ClassifierChain(), LabelPowerset()], disable_warnings=True, with_dwarf=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
