{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skmultilearn.problem_transform import BinaryRelevance, ClassifierChain\n",
    "    \n",
    "from common.featuresutils import load_features\n",
    "from common.flagutils import load_flag_list\n",
    "from common.flagutils import load_o3_flags\n",
    "from common.flagutils import build_config\n",
    "from common.flagutils import get_cmd_string_from_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Benchmark</th>\n",
       "      <th>Flags</th>\n",
       "      <th>Type</th>\n",
       "      <th>RunId</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BT.C</td>\n",
       "      <td>-O3</td>\n",
       "      <td>O3</td>\n",
       "      <td>-1</td>\n",
       "      <td>8685.049255</td>\n",
       "      <td>44.226147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BT.C</td>\n",
       "      <td>-O3 -faggressive-loop-optimizations -falign-fu...</td>\n",
       "      <td>test</td>\n",
       "      <td>80</td>\n",
       "      <td>8776.150006</td>\n",
       "      <td>43.287949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BT.C</td>\n",
       "      <td>-O3 -faggressive-loop-optimizations -falign-fu...</td>\n",
       "      <td>test</td>\n",
       "      <td>82</td>\n",
       "      <td>8918.038919</td>\n",
       "      <td>43.911705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BT.C</td>\n",
       "      <td>-O3 -faggressive-loop-optimizations -falign-fu...</td>\n",
       "      <td>test</td>\n",
       "      <td>83</td>\n",
       "      <td>8861.715663</td>\n",
       "      <td>43.573321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BT.C</td>\n",
       "      <td>-O3 -faggressive-loop-optimizations -falign-fu...</td>\n",
       "      <td>test</td>\n",
       "      <td>84</td>\n",
       "      <td>8867.013709</td>\n",
       "      <td>43.667829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Benchmark                                              Flags  Type  RunId  \\\n",
       "0      BT.C                                                -O3    O3     -1   \n",
       "1      BT.C  -O3 -faggressive-loop-optimizations -falign-fu...  test     80   \n",
       "2      BT.C  -O3 -faggressive-loop-optimizations -falign-fu...  test     82   \n",
       "3      BT.C  -O3 -faggressive-loop-optimizations -falign-fu...  test     83   \n",
       "4      BT.C  -O3 -faggressive-loop-optimizations -falign-fu...  test     84   \n",
       "\n",
       "        Energy       Time  \n",
       "0  8685.049255  44.226147  \n",
       "1  8776.150006  43.287949  \n",
       "2  8918.038919  43.911705  \n",
       "3  8861.715663  43.573321  \n",
       "4  8867.013709  43.667829  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('CE.results.csv')\n",
    "data.loc[:, 'Energy'] *= 1e-6 # Convert energy to Joules\n",
    "data.loc[:, 'Benchmark'] = data['Benchmark'].str.replace('.x', '')\n",
    "\n",
    "average_data = data.groupby(['Benchmark','Flags', 'Type', 'RunId'], as_index=False).agg({'Energy':'mean', 'Time':'mean'})\n",
    "average_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n"
     ]
    }
   ],
   "source": [
    "all_flags = load_flag_list()\n",
    "print(len(all_flags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_configuration(variable, benchmark, average_data):\n",
    "    benchmark_data = average_data.loc[average_data[\"Benchmark\"] == benchmark]\n",
    "    min_index = benchmark_data[variable].idxmin()\n",
    "    return benchmark_data.loc[min_index][\"Flags\"]\n",
    "\n",
    "\n",
    "def get_o3_config():\n",
    "    return get_cmd_string_from_config(build_config(all_flags, load_o3_flags(), '-O3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nab' 'imagick' 'botsalgn' 'botsspar' 'kdtree' 'smithwa' 'BT.C' 'UA.C'\n",
      " 'swim' 'EP.D']\n"
     ]
    }
   ],
   "source": [
    "benchmarks = data[\"Benchmark\"].unique()\n",
    "print(benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 65)\n",
      "(10, 187)\n"
     ]
    }
   ],
   "source": [
    "X = load_features([b.split('.')[0] for b in benchmarks])\n",
    "y = []\n",
    "\n",
    "for benchmark in benchmarks:\n",
    "    config_str = best_configuration('Energy', benchmark, average_data)\n",
    "    if config_str == '-O3':\n",
    "        config_str = get_o3_config()\n",
    "    \n",
    "    labels = []\n",
    "    \n",
    "    config = config_str[4:].split(' ')\n",
    "    for i, flag in enumerate(config):\n",
    "        if flag == all_flags[i]:\n",
    "            labels.append(1) # Flag is turned on\n",
    "        elif flag == '-fno-' + all_flags[i][2:]:\n",
    "            labels.append(0) # FLag is turned off -fno\n",
    "        else:\n",
    "            print(\"ERROR:\" + flag)\n",
    "    \n",
    "    y.append(labels)\n",
    "\n",
    "y = np.array(y)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 85)\n"
     ]
    }
   ],
   "source": [
    "cols_to_remove = []\n",
    "for i in range(y.shape[1]):\n",
    "    unique, counts = np.unique(y[:, i], return_counts=True)\n",
    "    \n",
    "    if (len(unique) == 1) or (1 in counts):\n",
    "        cols_to_remove.append(i)\n",
    "        \n",
    "small_y = np.delete(y, cols_to_remove, axis=1)\n",
    "print(small_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(classifier, parameters):\n",
    "    gs = GridSearchCV(classifier, parameters, cv=10, scoring='f1_macro', n_jobs=-1)\n",
    "    gs.fit(normalised_X, small_y)\n",
    "\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Best F1 Score: 0.6376470588235293\n",
      "{'classifier': SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), 'classifier__C': 0.01}\n",
      "Gaussian Best F1 Score: 0.6517647058823529\n",
      "{'classifier': SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=1e-09, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), 'classifier__C': 0.01, 'classifier__gamma': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'classifier': [SVC(kernel='linear')],\n",
    "    'classifier__C': np.logspace(-2, 10, 13)\n",
    "}\n",
    "linear_gs = grid_search(BinaryRelevance(), parameters)\n",
    "\n",
    "print(f\"Linear Best F1 Score: {linear_gs.best_score_}\")\n",
    "print(linear_gs.best_params_)\n",
    "\n",
    "parameters = {\n",
    "    'classifier': [SVC(kernel='rbf')],\n",
    "    'classifier__C': np.logspace(-2, 10, 13),\n",
    "    'classifier__gamma':  np.logspace(-9, 3, 13)\n",
    "}\n",
    "gaussian_gs = grid_search(BinaryRelevance(), parameters)\n",
    "print(f\"Gaussian Best F1 Score: {gaussian_gs.best_score_}\")\n",
    "print(gaussian_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Best F1 Score: 0.6341176470588235\n",
      "{'classifier': SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), 'classifier__C': 0.01}\n",
      "Gaussian Best F1 Score: 0.6529411764705882\n",
      "{'classifier': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=1.0, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), 'classifier__C': 1.0, 'classifier__gamma': 1.0}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'classifier': [SVC(kernel='linear')],\n",
    "    'classifier__C': np.logspace(-2, 10, 13)\n",
    "}\n",
    "linear_gs = grid_search(ClassifierChain(), parameters)\n",
    "\n",
    "print(f\"Linear Best F1 Score: {linear_gs.best_score_}\")\n",
    "print(linear_gs.best_params_)\n",
    "\n",
    "parameters = {\n",
    "    'classifier': [SVC(kernel='rbf')],\n",
    "    'classifier__C': np.logspace(-2, 10, 13),\n",
    "    'classifier__gamma':  np.logspace(-9, 3, 13)\n",
    "}\n",
    "gaussian_gs = grid_search(ClassifierChain(), parameters)\n",
    "print(f\"Gaussian Best F1 Score: {gaussian_gs.best_score_}\")\n",
    "print(gaussian_gs.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
