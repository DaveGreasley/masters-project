{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_data = [\n",
    "#      (pd.read_csv(\"fixed_flags/fix_flags.bc.20180813-135517.false.csv\"), 'false'),\n",
    "    (pd.read_csv(\"fixed_flags/fix_flags.bc.20180812-142333.spread.csv\"), 'spread'),\n",
    "    (pd.read_csv(\"fixed_flags/fix_flags.bc.20180813-025019.close.csv\"), 'close'),\n",
    "    (pd.read_csv(\"fixed_flags/fix_flags.bc.20180814-034312.true.csv\"), 'true')\n",
    "]\n",
    "npb_data = [\n",
    "#      (pd.read_csv(\"fixed_flags/fix_flags.bc.20180813-124212.false.csv\"), 'false'),\n",
    "    (pd.read_csv(\"fixed_flags/fix_flags.bc.20180812-142221.spread.csv\"), 'spread'),\n",
    "    (pd.read_csv(\"fixed_flags/fix_flags.bc.20180812-204259.close.csv\"), 'close'),\n",
    "    (pd.read_csv(\"fixed_flags/fix_flags.bc.20180814-034012.true.csv\"), 'true')\n",
    "]\n",
    "\n",
    "parboil_data = [\n",
    "#      (pd.read_csv(\"fixed_flags/fix_flags.bc.20180826-200104.false.csv\"), 'false'),\n",
    "    (pd.read_csv(\"fixed_flags/fix_flags.bc.20180826-232755.spread.csv\"), 'spread'),\n",
    "    (pd.read_csv(\"fixed_flags/fix_flags.bc.20180826-220610.close.csv\"), 'close'),\n",
    "    (pd.read_csv(\"fixed_flags/fix_flags.bc.20180826-180300.true.csv\"), 'true')\n",
    "]\n",
    "\n",
    "rodinia_data = [\n",
    "    (pd.read_csv(\"fixed_flags/fix_flags.bc.20180830-034651.true.csv\"), 'true')\n",
    "]\n",
    "\n",
    "for frame in parboil_data + npb_data + spec_data + rodinia_data:\n",
    "    frame[0].loc[:, 'Energy'] *= 1e-6 # Convert energy to Joules\n",
    "    frame[0].loc[:, 'Benchmark'] = frame[0]['Benchmark'].str.replace('.x', '')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spec_data[0][0][\"Benchmark\"].unique())\n",
    "print(npb_data[0][0][\"Benchmark\"].unique())\n",
    "print(parboil_data[0][0][\"Benchmark\"].unique())\n",
    "print(rodinia_data[0][0][\"Benchmark\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = ['O1', 'O2', 'O3']\n",
    "markers = ['x', 'o', 'v']\n",
    "\n",
    "def compare_results(frames, benchmarks=None):\n",
    "    if benchmarks == None:\n",
    "        benchmarks = frames[0][0][\"Benchmark\"].unique()\n",
    "    \n",
    "    rows = len(benchmarks)\n",
    "    columns = len(frames)\n",
    "\n",
    "    fig = plt.figure(figsize=(8.0*columns, 6.0*rows))\n",
    "    \n",
    "    benchmark_axes = {}\n",
    "    \n",
    "    for i, (frame, label) in enumerate(frames):\n",
    "        plot_pos = i + 1\n",
    "        \n",
    "#         for benchmark in benchmarks:\n",
    "        for benchmark in benchmarks:\n",
    "            benchmark_data = frame[frame[\"Benchmark\"] == benchmark]\n",
    "            \n",
    "            if benchmark in benchmark_axes:\n",
    "                ax = fig.add_subplot(rows, columns, plot_pos, sharex=benchmark_axes[benchmark], sharey=benchmark_axes[benchmark])\n",
    "            else:\n",
    "                ax = fig.add_subplot(rows, columns, plot_pos)\n",
    "                benchmark_axes[benchmark] = ax\n",
    "                \n",
    "            plot_pos += columns\n",
    "            \n",
    "            for k, flag in enumerate(flags):\n",
    "\n",
    "                marker = markers[k]\n",
    "\n",
    "                flag_data = benchmark_data[benchmark_data[\"Flags\"] == \"-\" + flag]\n",
    "\n",
    "                x = flag_data[\"Time\"].values\n",
    "                y = flag_data[\"Energy\"].values\n",
    "\n",
    "                ax.scatter(x, y, marker=marker, label=flag)\n",
    "            \n",
    "            ax.legend()\n",
    "            ax.set_title(benchmark + ', proc_bind=' + label)\n",
    "            ax.set_xlabel('Time (s)')\n",
    "            ax.set_ylabel('Energy (J)')\n",
    "            ax.grid()\n",
    "\n",
    "def plot_single_benchmark(frames, benchmark, proc_bind):\n",
    "    frame = None\n",
    "    for f in frames:\n",
    "        if f[1] == proc_bind:\n",
    "            frame = f[0]\n",
    "            \n",
    "    benchmark_data = frame[frame[\"Benchmark\"].str.lower() == benchmark]\n",
    "    \n",
    "    plt.figure()\n",
    "    for k, flag in enumerate(flags):\n",
    "        marker = markers[k]\n",
    "\n",
    "        flag_data = benchmark_data[benchmark_data[\"Flags\"] == \"-\" + flag]\n",
    "\n",
    "        x = flag_data[\"Time\"].values\n",
    "        y = flag_data[\"Energy\"].values\n",
    "\n",
    "        plt.scatter(x, y, marker=marker, label=flag)\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.title('Energy vs Time for standard optimisation levels for ' + benchmark)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Energy (J)')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare_results(npb_data)\n",
    "# compare_results(spec_data)\n",
    "# compare_results(parboil_data)\n",
    "# compare_results(rodinia_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_energy_time(frames, proc_bind):\n",
    "    frame = None\n",
    "    for f in frames:\n",
    "        if f[1] == proc_bind:\n",
    "            frame = f[0]\n",
    "            \n",
    "    average_energy = np.mean(frame['Energy'])\n",
    "    average_time = np.mean(frame['Time'])\n",
    "    \n",
    "    return average_energy, average_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(average_energy_time(npb_data, 'close'))\n",
    "print(average_energy_time(npb_data, 'spread'))\n",
    "print(average_energy_time(npb_data, 'true'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(average_energy_time(spec_data, 'close'))\n",
    "print(average_energy_time(spec_data, 'spread'))\n",
    "print(average_energy_time(spec_data, 'true'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_benchmark(npb_data, 'bt.c', 'true')\n",
    "plot_single_benchmark(npb_data, 'is.d', 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(data, variable):\n",
    "    mean = np.mean(data[variable].values)\n",
    "    median = np.median(data[variable].values)\n",
    "    min = np.min(data[variable].values)\n",
    "    max = np.max(data[variable].values)\n",
    "    range = max - min\n",
    "    relative_range = range / mean * 100\n",
    "    std = np.std(data[variable].values)\n",
    "    coeff_var = std / mean * 100\n",
    "    \n",
    "    return [mean, median, min, max, range, relative_range, std, coeff_var]\n",
    "\n",
    "def summary_frame(array):\n",
    "    return pd.DataFrame(array[:,1:], \n",
    "                       index=array[:,0],\n",
    "                       dtype=float,\n",
    "                       columns=['Mean', 'Median', 'Min', 'Max', 'Range', 'Relative Range', 'Std', 'CV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_true_data = spec_data[-1][0]\n",
    "npb_true_data = npb_data[-1][0]\n",
    "parboil_true_data = parboil_data[-1][0]\n",
    "rodinia_true_data = rodinia_data[-1][0]\n",
    "true_data = pd.concat([spec_true_data, npb_true_data, parboil_true_data, rodinia_true_data])\n",
    "\n",
    "summary_list_time = []\n",
    "summary_list_energy = []\n",
    "\n",
    "for benchmark in true_data[\"Benchmark\"].unique():\n",
    "    benchmark_data = true_data[(true_data[\"Benchmark\"] == benchmark) & (true_data[\"Flags\"] == '-O3')]\n",
    "    \n",
    "    summary_list_time.append([benchmark] + summary(benchmark_data, 'Time'))\n",
    "    summary_list_energy.append([benchmark] + summary(benchmark_data, 'Energy'))\n",
    "\n",
    "summary_frame_time = summary_frame(np.array(summary_list_time))\n",
    "summary_frame_energy = summary_frame(np.array(summary_list_energy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_frame_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_benchmarks(metric, threshold_percentage=2):\n",
    "    low_variation_time = summary_frame_time[summary_frame_time[metric] <= threshold_percentage].index\n",
    "    low_variation_energy = summary_frame_energy[summary_frame_energy[metric] <= threshold_percentage].index\n",
    "    return set(low_variation_time).intersection(set(low_variation_energy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks_for_ce = stable_benchmarks('CV')\n",
    "print(len(benchmarks_for_ce))\n",
    "print(benchmarks_for_ce)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
